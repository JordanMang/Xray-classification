{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray Classification of Pneumionia using a Neural Network\n",
    "\n",
    "#### Authors: Mitch Allison, Jordan Mang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview:\n",
    "\n",
    "Pneumonia affects nearly one out of every fifteen people worldwide annually. For most people contracting pneumonia isn't life threatening but of the near half billion people that contract it 2.5 million pass from this totally treatable illness. At most risk are seniors and children under 5 years old, for these people it is important to identify this illness in it's early stages before it has time to develop into a life threating situation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem:\n",
    "\n",
    "St. Jude's Children's Hospital recognizes that in America pneumonia is not a leading cause of death in children but that world-wide every 43 seconds a child dies of this treatable disease. Most of these deaths are taking place in countries of Sub-Saharan Africa like the Congo, Guinea, and the Central African Republic.\n",
    "\n",
    "By partnering with Europa, a company who specializes in handhelp X-Ray machines, St. Jude's plans on sending simple laptops and handheld X-Ray machines to countries with high mortality rates related to pneunomia. \n",
    "\n",
    "Due to a lack of medical staff who can properly identify pneumonia, St. Judes has asked us to build a machine learning model that can quickly and accurately identify pneumonia with x-ray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding Part 1:\n",
    "\n",
    "Our model has been trained off of nearly 6,000 chest X-Ray's supplied to us through [Kaggle.com](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia). This data was originally gathered by the Guangzhou Women and Childrenâ€™s Medical Center and consist of X-Ray's of children one to five years of age.\n",
    "\n",
    "These photos have been pre-cleaned and sorted according to class(healthy/pneumonia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Model:\n",
    "\n",
    "For our first model we created a dummy model that would predict the majority class(Pneumonia) for all input photos.(More info can be found in the Dummy_model notebook)\n",
    "\n",
    "We also created a function that would load the pictures into the notebook at a resized resolution, which we would end up using for the more complex models later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model imports\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Photo_Data(location, num_photos):\n",
    "    '''\n",
    "    Returns photos from data folder(resized, grayscaled) and binary class.\n",
    "    \n",
    "    '''\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    data = datagen.flow_from_directory(\n",
    "        location,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=num_photos,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting images and labels for models\n",
    "train_photos = Get_Photo_Data('./data/archive/chest_xray/train/', 5216)\n",
    "test_photos = Get_Photo_Data('./data/archive/chest_xray/test/', 624)\n",
    "val_photos = Get_Photo_Data('./data/archive/chest_xray/val/', 16)\n",
    "\n",
    "# unpack images and labels for CM/dummy model\n",
    "train_data, train_labels = next (train_photos)\n",
    "test_data, test_labels = next (test_photos)\n",
    "val_data, val_labels = next (val_photos)\n",
    "\n",
    "# create DummyModel on most frequent class\n",
    "dummy_model =  DummyClassifier(strategy='most_frequent')\n",
    "dummy_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model accuracy: 0.625\n",
      "Dummy Model recall: 1.0\n",
      "Dummy Model precision: 0.625\n"
     ]
    }
   ],
   "source": [
    "# creating predictions to evalaute model \n",
    "y_pred = (dummy_model.predict(test_data))\n",
    "\n",
    "# getting metrics for model\n",
    "acc = dummy_model.score(test_data, test_labels)\n",
    "rec = metrics.recall_score(test_labels,y_pred)\n",
    "pre = metrics.precision_score(test_labels,y_pred)\n",
    "\n",
    "print(f\"Dummy Model accuracy: {acc}\")\n",
    "print(f\"Dummy Model recall: {rec}\")\n",
    "print(f\"Dummy Model precision: {pre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Model Performance Metrics:\n",
    "\n",
    "#### NOTE: All model performance metrics are on the test set of unseen data.\n",
    "\n",
    "![DM_CM](./graphs/CM_DUMMY.jpg)\n",
    "\n",
    "We can see that our dummy model has an accuracy of 62.5%, as this model predicts the majority class only.\n",
    "\n",
    "The next step is to create a first simple model(FSM) using a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM:\n",
    "\n",
    "For our FSM, we created the simplest possible neural network. We loaded in the data without using the function.\n",
    "\n",
    "The FSM neural network detailed below had the following layers:\n",
    "1. Input: Conv2D layer taking in a 2d color photo of shape 256x256(activation=relu)\n",
    "2. Pooling layer for Conv2D layer\n",
    "3. Flatten layer\n",
    "4. Hidden dense layer(activation=relu)\n",
    "5. Output layer(activation=Sigmoid)\n",
    "\n",
    "To fit the model we did so across 30 batches due to the file size, and used 10 epochs.\n",
    "\n",
    "Our FSM code is contained below but this code is commented out for the following reasons:\n",
    "1. Loading in the 1.6gb of photos multiple times can cause memory issues and takes time\n",
    "2. Fitting the model takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSM imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, Sequential\n",
    "from tensorflow.keras import models, layers, optimizers, regularizers\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get photos for model training\n",
    "# train = tf.keras.utils.image_dataset_from_directory('./data/archive/chest_xray/chest_xray/train')\n",
    "# test = tf.keras.utils.image_dataset_from_directory('./data/archive/chest_xray/chest_xray/test')\n",
    "# val = tf.keras.utils.image_dataset_from_directory('./data/archive/chest_xray/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers to model\n",
    "# input layer\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', padding = 'same', input_shape=(256,256,3)))\n",
    "\n",
    "# add pooling layer(takes max from input window)\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# flattens 2d to 1d\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# add dense layer\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "# add output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with adam for binary model\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "# history = model.fit(train,\n",
    "#                batch_size=30,\n",
    "#                epochs=10,\n",
    "#                validation_data=(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM Performance Metrics:\n",
    "\n",
    "![FSM_LOSS](./graphs/LOSS_FSM.jpg)\n",
    "\n",
    "![FSM_ACCURACY](./graphs/ACCURACY_FSM.jpg)\n",
    "\n",
    "Our FSM is an improvement over the dummy model, with a precision of 71%, accuracy of 74%, and recall of 98%. It's expected that recall will drop a bit as the model will likely not catch 100% of positive cases unless it is overfit.\n",
    "\n",
    "We can see from the curves on the graphs above that running additional epochs is unlikely to improve model performance.\n",
    "\n",
    "We can also see that our model is only marginally better than the dummy model, and so will require iteration to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Iteration:\n",
    "\n",
    "After creating our FSM, we continued to iterate models to create more accurate models. The code for these models can be found in the model notebooks listed #2 - #6. We changed only a couple of things per iteration to make sure we had enough constant variables. If we saw an improvement we kept the change, and noted why it was kept.\n",
    "\n",
    "2. Nodes in initial layer increased to 32.\n",
    "3. \n",
    "    A. Added the function to load photos back in.(kept: simplify load-in process)\n",
    "    B. Change input shape to (150, 150, 1).(kept: model speed was much faster)\n",
    "    C. Input layer nodes changed to 64.(kept: model metrics marginally improved)\n",
    "4. \n",
    "    A. Decreased batch size by half(30 to 15)\n",
    "    B. Increased epochs(10 to 20)\n",
    "5. Added 2nd convolutional stack(Conv2D + MaxPooling2D) behind 1st convolutional layer(kept: model metrics marginally improved)\n",
    "6. Added 0.15 dropout to the dense layer(kept: model metrics marginally improved)\n",
    "7. Combine and resplit train/test/validate to get more suitable numbers for each.(kept: achieved final model performance metrics)\n",
    "\n",
    "![MODEL_ITERATION](./graphs/MODEL_ITERATION.jpg)\n",
    "\n",
    "For most models tested during the iteration process, the performance of the model was only improving ever so slightly, or in a different direction that would decrease the score from another metric(ex. trading off 0.005 accuracy for 0.005 loss). It wasn't until we changed the dataset where the model was able to reach the performance we were looking for, without having an overly complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding Part 2:\n",
    "\n",
    "The original set has a class imbalance of 1(Normal):2.7(Pneumonia). The provided data was pre-split into train/test/validate sets, but with only 16 images in the validate set.\n",
    "\n",
    "When we chose to combine and rebalance the photos to a ratio to .65/.2/.15 we saw our model performance improve dramatically and reach the metrics that we were looking for. After combining the dataset manually, you can use the following function to split the data.\n",
    "\n",
    "This code is commented out so as not to split the data again locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tool will need to be pip installed if not installed already\n",
    "# !pip install split-folders\n",
    "\n",
    "# Import\n",
    "# import splitfolders\n",
    "\n",
    "# splitfolders.ratio(\"./data/combined/\", output=\"combined_ttv\", seed=42, ratio=(.65, .15, .2), group_prefix=None, move=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Code:\n",
    "\n",
    "We've put the code required here for the final model, but have commented out code where required to save time and memory.\n",
    "\n",
    "The full final model code can be found in the FinalModel notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, Sequential\n",
    "from tensorflow.keras import models, layers, optimizers, regularizers\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Photo_Data(location, num_photos):\n",
    "    '''\n",
    "    Returns photos from data folder(resized, grayscaled) and binary class.\n",
    "    \n",
    "    '''\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    data = datagen.flow_from_directory(\n",
    "        location,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=num_photos,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting images and labels for models\n",
    "# train_photos = Get_Photo_Data('./combined_ttv/train/', 3805)\n",
    "# test_photos = Get_Photo_Data('./combined_ttv/test/', 1174)\n",
    "# val_photos = Get_Photo_Data('./combined_ttv/val/', 877)\n",
    "\n",
    "# # unpack images and labels for CM/dummy model\n",
    "# train_data, train_labels = next (train_photos)\n",
    "# test_data, test_labels = next (test_photos)\n",
    "# val_data, val_labels = next (val_photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "# input layer\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu', padding = 'same', input_shape=(150,150,1)))\n",
    "\n",
    "# add pooling layer(takes max from input window)\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# add 2nd Conv2D layer\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu', padding = 'same'))\n",
    "\n",
    "# add pooling layer(takes max from above Conv2D layer)\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# flattens 2d to 1d\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# add dense layer\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "# add dropout layer\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# add output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model with adam for binary model\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy',\n",
    "                                                                    Precision(name='precision'),\n",
    "                                                                    Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "# history = model.fit(train_data,\n",
    "#                train_labels,\n",
    "#                batch_size=30,\n",
    "#                epochs=10,\n",
    "#                validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Performance Metrics:\n",
    "\n",
    "![FM_LOSS](./graphs/LOSS_FINAL.jpg)\n",
    "\n",
    "![FM_ACCURACY](./graphs/ACCURACY_FINAL.jpg)\n",
    "\n",
    "Our final model is able to achieve metrics which are satisfactory to us considering the amount of model complexity and time for the project. We have saved this model in the model folder for outside use.\n",
    "\n",
    "- Accuracy: 0.95\n",
    "- Precision: 0.96\n",
    "- Recall: 0.98\n",
    "\n",
    "Of these stats, the most important one to us is recall. We're more ok with additional false positives than false negatives considering the use case: it's safer to incorrectly identify someone as having pneumonia and not having the disease than missing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "1. Continue to iterate for better model performance: With additional time we could continue to iterate the model to see if we could improve model metrics\n",
    "2. Augment image data: Data is king with neural networks, and although we have more than a gigabyte of images to train the neural network on, more data is always better. By augmenting the given photos(applying shake, rotate, inversion, etc) we could increase our dataset by 4 fold.\n",
    "3. Deploy model with hand-held X-ray machines: We could deploy this model with hand-held X-ray machines to those in need to be able to identify pneumonia with an X-ray without trained medical staff required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
